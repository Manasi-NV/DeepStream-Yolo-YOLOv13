{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepStream YOLOv13 Object Detection\n",
        "\n",
        "This notebook runs **YOLOv13** detection using [DeepStream-Yolo](https://github.com/marcoslucianops/DeepStream-Yolo) with NVIDIA DeepStream SDK.\n",
        "\n",
        "**Run this notebook inside the DeepStream container** (e.g. `manasi1096/deepstream8-python:h100`) where `/workspace` is mounted to your project directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup paths and install build tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Resolve project root — the notebook lives in DeepStream-Yolo-YOLOv13/\n",
        "# Inside the container, /workspace is mounted from the host's /home/nvidia\n",
        "NOTEBOOK_DIR = Path(\"/workspace/DeepStream-Yolo-YOLOv13\")\n",
        "if not NOTEBOOK_DIR.exists():\n",
        "    NOTEBOOK_DIR = Path(\"/home/nvidia/DeepStream-Yolo-YOLOv13\")\n",
        "DS_YOLO_DIR = NOTEBOOK_DIR / \"DeepStream-Yolo\"\n",
        "\n",
        "os.chdir(NOTEBOOK_DIR)\n",
        "\n",
        "# Clone DeepStream-Yolo if not present\n",
        "if not DS_YOLO_DIR.exists():\n",
        "    ! git clone --depth 1 https://github.com/marcoslucianops/DeepStream-Yolo.git {DS_YOLO_DIR}\n",
        "\n",
        "# Copy pre-made config files into DeepStream-Yolo\n",
        "CONFIGS_DIR = NOTEBOOK_DIR / \"configs\"\n",
        "if CONFIGS_DIR.exists():\n",
        "    for cfg in CONFIGS_DIR.glob(\"*.txt\"):\n",
        "        shutil.copy2(cfg, DS_YOLO_DIR / cfg.name)\n",
        "        print(f\"Copied config: {cfg.name}\")\n",
        "\n",
        "print(\"Project root:\", NOTEBOOK_DIR)\n",
        "print(\"DeepStream-Yolo:\", DS_YOLO_DIR)\n",
        "assert DS_YOLO_DIR.exists(), \"DeepStream-Yolo not found.\"\n",
        "\n",
        "# Install build-essential if needed (for compiling nvdsinfer custom lib)\n",
        "! apt-get update -qq && apt-get install -y -qq build-essential > /dev/null 2>&1\n",
        "print(\"Build tools ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get YOLOv13 ONNX model\n",
        "\n",
        "Clones the [iMoonLab/yolov13](https://github.com/iMoonLab/yolov13) repo, installs it as a package (it's a fork of ultralytics with custom YOLOv13 modules), downloads `yolov13s.pt`, and exports to ONNX using the DeepStream-Yolo converter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "YOLOV13_DIR = NOTEBOOK_DIR / \"yolov13\"\n",
        "YOLOV13_DIR.mkdir(exist_ok=True)\n",
        "os.chdir(YOLOV13_DIR)\n",
        "\n",
        "# Clone YOLOv13 repo (iMoonLab fork of ultralytics with custom arch)\n",
        "if not (YOLOV13_DIR / \"setup.py\").exists() and not (YOLOV13_DIR / \"pyproject.toml\").exists():\n",
        "    ! git clone --depth 1 https://github.com/iMoonLab/yolov13.git repo\n",
        "    if (YOLOV13_DIR / \"repo\").exists():\n",
        "        ! cp -r repo/* repo/.* . 2>/dev/null; rm -rf repo\n",
        "\n",
        "# IMPORTANT: Install the yolov13 repo as a package — it is a fork of ultralytics\n",
        "# with custom YOLOv13 modules. Vanilla ultralytics cannot load yolov13s.pt.\n",
        "! pip install -e . 2>&1 | tail -5\n",
        "! pip install -q onnx onnxslim onnxruntime onnxscript huggingface_hub\n",
        "\n",
        "# Download YOLOv13s weights from releases\n",
        "PT_FILE = YOLOV13_DIR / \"yolov13s.pt\"\n",
        "if not PT_FILE.exists():\n",
        "    ! wget -q https://github.com/iMoonLab/yolov13/releases/download/yolov13/yolov13s.pt -O yolov13s.pt\n",
        "print(\"Weights downloaded:\", PT_FILE.exists())\n",
        "\n",
        "# Copy DeepStream export script and run ONNX export\n",
        "# NOTE: Do NOT use --simplify; the simplifier corrupts the external-data ONNX.\n",
        "#       Use opset 18 (torch 2.10+ requires it).\n",
        "EXPORT_SCRIPT = DS_YOLO_DIR / \"utils\" / \"export_yoloV13.py\"\n",
        "assert EXPORT_SCRIPT.exists(), f\"Export script not found at {EXPORT_SCRIPT}\"\n",
        "! cp {EXPORT_SCRIPT} .\n",
        "! python3 export_yoloV13.py -w yolov13s.pt --dynamic --opset 18\n",
        "\n",
        "# The new PyTorch ONNX exporter stores weights externally (yolov13s.onnx.data).\n",
        "# Inline them into a single file so TensorRT can parse it.\n",
        "import onnx\n",
        "model_onnx = onnx.load(\"yolov13s.onnx\", load_external_data=True)\n",
        "onnx.save(model_onnx, str(DS_YOLO_DIR / \"yolov13s.onnx\"))\n",
        "print(f\"Inlined ONNX saved: {(DS_YOLO_DIR / 'yolov13s.onnx').stat().st_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# Copy labels\n",
        "if (YOLOV13_DIR / \"labels.txt\").exists():\n",
        "    ! cp labels.txt {DS_YOLO_DIR}/\n",
        "print(\"ONNX model and labels ready in DeepStream-Yolo.\")\n",
        "\n",
        "os.chdir(NOTEBOOK_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build DeepStream custom inference lib\n",
        "\n",
        "Compile `nvdsinfer_custom_impl_Yolo` for your CUDA/DeepStream version (DeepStream 8.0 → CUDA_VER=12.8 on x86)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "os.chdir(DS_YOLO_DIR)\n",
        "\n",
        "# DeepStream 8.0 x86 = 12.8; for Jetson/other see README\n",
        "os.environ[\"CUDA_VER\"] = \"12.8\"\n",
        "! make -C nvdsinfer_custom_impl_Yolo clean\n",
        "! make -C nvdsinfer_custom_impl_Yolo\n",
        "\n",
        "SO_PATH = DS_YOLO_DIR / \"nvdsinfer_custom_impl_Yolo\" / \"libnvdsinfer_custom_impl_Yolo.so\"\n",
        "print(\"Lib built:\", SO_PATH.exists())\n",
        "os.chdir(NOTEBOOK_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run DeepStream app with YOLOv13\n",
        "\n",
        "Runs `deepstream-app` with the YOLOv13 config. Input is the default DeepStream sample video. Output is saved to `output_yolov13.mp4` (file sink, no display needed). First run may take several minutes to build the TensorRT engine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "os.chdir(DS_YOLO_DIR)\n",
        "\n",
        "APP_CONFIG = \"deepstream_app_config_yolov13.txt\"\n",
        "assert Path(APP_CONFIG).exists(), f\"{APP_CONFIG} not found in {DS_YOLO_DIR}\"\n",
        "\n",
        "print(\"Running: deepstream-app -c\", APP_CONFIG)\n",
        "print(\"First run can take 5–10+ min for TensorRT engine build.\")\n",
        "print(\"Output will be saved to: output_yolov13.mp4\")\n",
        "! deepstream-app -c {APP_CONFIG}\n",
        "\n",
        "# Check output\n",
        "output_file = DS_YOLO_DIR / \"output_yolov13.mp4\"\n",
        "if output_file.exists():\n",
        "    size_mb = output_file.stat().st_size / (1024 * 1024)\n",
        "    print(f\"\\nOutput saved: {output_file} ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"\\nWarning: output file not found — check the logs above for errors.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Run on your own video\n",
        "\n",
        "Edit `[source0]` in `DeepStream-Yolo/deepstream_app_config_yolov13.txt`:\n",
        "- `uri=file:///path/to/your/video.mp4`\n",
        "\n",
        "Then run the cell above again."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}